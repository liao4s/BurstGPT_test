<<<<<<< HEAD
{"0": {"event_name": "Query", "start_timestamp": 13988294.043526229, "env_timestamp": 13988516.949959377, "during": "222.906 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 1024}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 1000.0, 'prompt_num': 500}", "log time": "2024-10-20 11:39:22.405945"}{"0": {"event_name": "Query", "start_timestamp": 13989085.70031688, "env_timestamp": 13989116.67068023, "during": "30.97 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 1024}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 50, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 1000.0, 'prompt_num': 50}", "log time": "2024-10-20 11:49:28.087820"}{"0": {"event_name": "Query", "start_timestamp": 13989308.297583397, "env_timestamp": 13989328.728312736, "during": "20.431 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 1024}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 50, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 1000.0, 'prompt_num': 50}", "log time": "2024-10-20 11:53:20.940733"}{"0": {"event_name": "Query", "start_timestamp": 13989577.525898676, "env_timestamp": 13989595.694381379, "during": "18.168 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 1024}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 50, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 1000.0, 'prompt_num': 50}", "log time": "2024-10-20 11:57:30.449815"}{"0": {"event_name": "Query", "start_timestamp": 13989660.71811988, "env_timestamp": 13989678.661690086, "during": "17.944 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 1024}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 50, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 1000.0, 'prompt_num': 50}", "log time": "2024-10-20 11:59:01.399520"}{"0": {"event_name": "Query", "start_timestamp": 13989940.039035762, "env_timestamp": 13989958.594898583, "during": "18.556 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 1024}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 50, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 1000.0, 'prompt_num': 50}", "log time": "2024-10-20 12:03:24.040763"}{"0": {"event_name": "Query", "start_timestamp": 13989940.039035762, "env_timestamp": 13989958.594898583, "during": "18.556 s"}, "model path": ["/root/autodl-tmp/Llama-3.2-1B"], "server_config": ["{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 1024}"], "prompt_config": ["{'seed': 0, 'surplus_prompts_num': 50, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 1000.0, 'prompt_num': 50}"], "log time": ["2024-10-20 12:03:24.040763"]}{"0": {"event_name": "Query", "start_timestamp": 13990065.446205651, "env_timestamp": 13990084.344042484, "during": "18.898 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 1024}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 50, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 1000.0, 'prompt_num': 50}", "log time": "2024-10-20 12:05:29.789689"}{"0": {"event_name": "Query", "start_timestamp": 13990231.129571471, "env_timestamp": 13990251.075854223, "during": "19.946 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 1024}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 50, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 1000.0, 'prompt_num': 500}", "log time": "2024-10-20 12:08:16.521648"}{"0": {"event_name": "Query", "start_timestamp": 13990296.650917048, "env_timestamp": 13990494.37365206, "during": "197.723 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 1024}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 1000.0, 'prompt_num': 500}", "log time": "2024-10-20 12:12:19.829032"}{"0": {"event_name": "Query", "start_timestamp": 14005182.843914673, "env_timestamp": 14005636.442654386, "during": "453.599 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 1024}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 100.0, 'prompt_num': 500}", "log time": "2024-10-20 16:24:39.622442"}{"0": {"event_name": "Query", "start_timestamp": 14005930.831174484, "env_timestamp": 14006151.125234757, "during": "220.294 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 1024}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 500.0, 'prompt_num': 500}", "log time": "2024-10-20 16:33:14.304658"}{"0": {"event_name": "Query", "start_timestamp": 14006225.741795337, "env_timestamp": 14006408.608820988, "during": "182.867 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 1024}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 1500.0, 'prompt_num': 500}", "log time": "2024-10-20 16:37:31.794361"}{"model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 1024}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 10.0, 'prompt_num': 500}", "log time": "2024-10-22 09:33:52.398786"}{"0": {"event_name": "Query", "start_timestamp": 14154306.32716372, "env_timestamp": 14154568.427363446, "during": "262.1 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 1024}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 200.0, 'prompt_num': 500}", "log time": "2024-10-22 09:46:51.606678"}{"0": {"event_name": "Query", "start_timestamp": 14154987.700188622, "env_timestamp": 14155166.740824288, "during": "179.041 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 1024}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 400.0, 'prompt_num': 500}", "log time": "2024-10-22 09:56:49.920469"}{"0": {"event_name": "Query", "start_timestamp": 14156165.809842965, "env_timestamp": 14156324.169218834, "during": "158.359 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 1024}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 600.0, 'prompt_num': 500}", "log time": "2024-10-22 10:16:07.348570"}{"0": {"event_name": "Query", "start_timestamp": 14156380.320262672, "env_timestamp": 14156528.423475012, "during": "148.103 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 1024}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 800.0, 'prompt_num': 500}", "log time": "2024-10-22 10:19:31.602973"}{"0": {"event_name": "Query", "start_timestamp": 14156639.641145945, "env_timestamp": 14156786.366848228, "during": "146.726 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 1024}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 900.0, 'prompt_num': 500}", "log time": "2024-10-22 10:23:49.546773"}{"0": {"event_name": "Query", "start_timestamp": 14265525.187131114, "env_timestamp": 14265678.199019445, "during": "153.012 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 128}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 1100.0, 'prompt_num': 500}", "log time": "2024-10-23 16:38:41.378738"}{"0": {"event_name": "Query", "start_timestamp": 14265895.535024406, "env_timestamp": 14265966.039253907, "during": "70.504 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 64}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 1100.0, 'prompt_num': 500}", "log time": "2024-10-23 16:43:29.219732"}{"0": {"event_name": "Query", "start_timestamp": 14266098.701381097, "env_timestamp": 14266139.224979252, "during": "40.524 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 64}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 1100.0, 'prompt_num': 500}", "log time": "2024-10-23 16:46:22.404438"}
=======
{"0": {"event_name": "Query", "start_timestamp": 13988294.043526229, "env_timestamp": 13988516.949959377, "during": "222.906 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 1024}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 1000.0, 'prompt_num': 500}", "log time": "2024-10-20 11:39:22.405945"}{"0": {"event_name": "Query", "start_timestamp": 13989085.70031688, "env_timestamp": 13989116.67068023, "during": "30.97 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 1024}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 50, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 1000.0, 'prompt_num': 50}", "log time": "2024-10-20 11:49:28.087820"}{"0": {"event_name": "Query", "start_timestamp": 13989308.297583397, "env_timestamp": 13989328.728312736, "during": "20.431 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 1024}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 50, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 1000.0, 'prompt_num': 50}", "log time": "2024-10-20 11:53:20.940733"}{"0": {"event_name": "Query", "start_timestamp": 13989577.525898676, "env_timestamp": 13989595.694381379, "during": "18.168 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 1024}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 50, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 1000.0, 'prompt_num': 50}", "log time": "2024-10-20 11:57:30.449815"}{"0": {"event_name": "Query", "start_timestamp": 13989660.71811988, "env_timestamp": 13989678.661690086, "during": "17.944 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 1024}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 50, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 1000.0, 'prompt_num': 50}", "log time": "2024-10-20 11:59:01.399520"}{"0": {"event_name": "Query", "start_timestamp": 13989940.039035762, "env_timestamp": 13989958.594898583, "during": "18.556 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 1024}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 50, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 1000.0, 'prompt_num': 50}", "log time": "2024-10-20 12:03:24.040763"}{"0": {"event_name": "Query", "start_timestamp": 13989940.039035762, "env_timestamp": 13989958.594898583, "during": "18.556 s"}, "model path": ["/root/autodl-tmp/Llama-3.2-1B"], "server_config": ["{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 1024}"], "prompt_config": ["{'seed': 0, 'surplus_prompts_num': 50, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 1000.0, 'prompt_num': 50}"], "log time": ["2024-10-20 12:03:24.040763"]}{"0": {"event_name": "Query", "start_timestamp": 13990065.446205651, "env_timestamp": 13990084.344042484, "during": "18.898 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 1024}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 50, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 1000.0, 'prompt_num': 50}", "log time": "2024-10-20 12:05:29.789689"}{"0": {"event_name": "Query", "start_timestamp": 13990231.129571471, "env_timestamp": 13990251.075854223, "during": "19.946 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 1024}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 50, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 1000.0, 'prompt_num': 500}", "log time": "2024-10-20 12:08:16.521648"}{"0": {"event_name": "Query", "start_timestamp": 13990296.650917048, "env_timestamp": 13990494.37365206, "during": "197.723 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 1024}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 1000.0, 'prompt_num': 500}", "log time": "2024-10-20 12:12:19.829032"}{"0": {"event_name": "Query", "start_timestamp": 14005182.843914673, "env_timestamp": 14005636.442654386, "during": "453.599 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 1024}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 100.0, 'prompt_num': 500}", "log time": "2024-10-20 16:24:39.622442"}{"0": {"event_name": "Query", "start_timestamp": 14005930.831174484, "env_timestamp": 14006151.125234757, "during": "220.294 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 1024}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 500.0, 'prompt_num': 500}", "log time": "2024-10-20 16:33:14.304658"}{"0": {"event_name": "Query", "start_timestamp": 14006225.741795337, "env_timestamp": 14006408.608820988, "during": "182.867 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 1024}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 1500.0, 'prompt_num': 500}", "log time": "2024-10-20 16:37:31.794361"}{"model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 1024}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 10.0, 'prompt_num': 500}", "log time": "2024-10-22 09:33:52.398786"}{"0": {"event_name": "Query", "start_timestamp": 14154306.32716372, "env_timestamp": 14154568.427363446, "during": "262.1 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 1024}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 200.0, 'prompt_num': 500}", "log time": "2024-10-22 09:46:51.606678"}{"0": {"event_name": "Query", "start_timestamp": 14154987.700188622, "env_timestamp": 14155166.740824288, "during": "179.041 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 1024}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 400.0, 'prompt_num': 500}", "log time": "2024-10-22 09:56:49.920469"}{"0": {"event_name": "Query", "start_timestamp": 14156165.809842965, "env_timestamp": 14156324.169218834, "during": "158.359 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 1024}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 600.0, 'prompt_num': 500}", "log time": "2024-10-22 10:16:07.348570"}{"0": {"event_name": "Query", "start_timestamp": 14156380.320262672, "env_timestamp": 14156528.423475012, "during": "148.103 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 1024}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 800.0, 'prompt_num': 500}", "log time": "2024-10-22 10:19:31.602973"}{"0": {"event_name": "Query", "start_timestamp": 14156639.641145945, "env_timestamp": 14156786.366848228, "during": "146.726 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 1024}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 900.0, 'prompt_num': 500}", "log time": "2024-10-22 10:23:49.546773"}{"0": {"event_name": "Query", "start_timestamp": 14347081.077127786, "env_timestamp": 14347088.895906692, "during": "7.819 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 64}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 50, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 1000.0, 'prompt_num': 50}", "log time": "2024-10-24 15:15:28.638279"}{"0": {"event_name": "Query", "start_timestamp": 14347174.610458724, "env_timestamp": 14347217.307368616, "during": "42.697 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 64}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 1000.0, 'prompt_num': 500}", "log time": "2024-10-24 15:17:37.059505"}{"model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 16}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 1000.0, 'prompt_num': 500}", "log time": "2024-10-24 15:19:53.868102"}{"0": {"event_name": "Query", "start_timestamp": 14347607.659300713, "env_timestamp": 14347647.042617576, "during": "39.383 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 16}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 1000.0, 'prompt_num': 500}", "log time": "2024-10-24 15:24:46.794125"}{"0": {"event_name": "Query", "start_timestamp": 14347708.269602558, "env_timestamp": 14347747.85513098, "during": "39.586 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 8}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 1000.0, 'prompt_num': 500}", "log time": "2024-10-24 15:26:27.607206"}
>>>>>>> 1aa4dd0c41f3668df3123a097608ec1b41df3067
{"0": {"event_name": "Query", "start_timestamp": 14502595.554211652, "env_timestamp": 14502635.085822023, "during": "39.532 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 128}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 1000.0, 'prompt_num': 500}", "log time": "2024-10-26 10:27:58.264696"}{"0": {"event_name": "Query", "start_timestamp": 14503206.074249642, "env_timestamp": 14503206.303436875, "during": "0.229 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 128}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 3, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 1000.0, 'prompt_num': 50000}", "log time": "2024-10-26 10:37:29.472303"}{"0": {"event_name": "Query", "start_timestamp": 14504161.330453629, "env_timestamp": 14504161.45302488, "during": "0.123 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 128}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 3, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 1000.0, 'prompt_num': 50000}", "log time": "2024-10-26 10:53:24.621836"}{"0": {"event_name": "Query", "start_timestamp": 14504621.495864814, "env_timestamp": 14504621.72677586, "during": "0.231 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 128}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 3, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 1000.0, 'prompt_num': 50000}", "log time": "2024-10-26 11:01:04.895684"}{"0": {"event_name": "Query", "start_timestamp": 14505321.731596883, "env_timestamp": 14505321.96291983, "during": "0.231 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 128}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 3, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 1000.0, 'prompt_num': 50000}", "log time": "2024-10-26 11:12:45.131899"}{"0": {"event_name": "Query", "start_timestamp": 14506265.912738144, "env_timestamp": 14506305.43139198, "during": "39.519 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 128}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 1000.0, 'prompt_num': 50000}", "log time": "2024-10-26 11:29:08.610601"}{"model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 128}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 1000.0, 'prompt_num': 50000}", "log time": "2024-10-26 11:40:22.012552"}{"model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 128}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 1000.0, 'prompt_num': 50000}", "log time": "2024-10-26 11:44:16.319021"}{"0": {"event_name": "Query", "start_timestamp": 14507283.35564726, "env_timestamp": 14507322.865905143, "during": "39.51 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 128}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 1000.0, 'prompt_num': 50000}", "log time": "2024-10-26 11:46:06.049942"}{"0": {"event_name": "Query", "start_timestamp": 14507339.598487278, "env_timestamp": 14507379.067153044, "during": "39.469 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 128}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 1000.0, 'prompt_num': 50000}", "log time": "2024-10-26 11:47:02.246695"}{"model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 128}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 1000.0, 'prompt_num': 50000}", "log time": "2024-10-26 11:47:26.959444"}{"0": {"event_name": "Query", "start_timestamp": 14512219.77080243, "env_timestamp": 14512259.349415276, "during": "39.579 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 128}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 1000.0, 'prompt_num': 50000}", "log time": "2024-10-26 13:08:22.528776"}{"0": {"event_name": "Query", "start_timestamp": 14512276.673334952, "env_timestamp": 14512316.098352294, "during": "39.425 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 128}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 1000.0, 'prompt_num': 50000}", "log time": "2024-10-26 13:09:19.277772"}{"0": {"event_name": "Query", "start_timestamp": 14512334.035999732, "env_timestamp": 14512373.5178029, "during": "39.482 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 128}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 1000.0, 'prompt_num': 50000}", "log time": "2024-10-26 13:10:16.697236"}{"0": {"event_name": "Query", "start_timestamp": 14513728.413868697, "env_timestamp": 14513767.860080753, "during": "39.446 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 128}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 1000.0, 'prompt_num': 50000}", "log time": "2024-10-26 13:33:31.039384"}{"0": {"event_name": "Query", "start_timestamp": 14513786.927682968, "env_timestamp": 14513826.363255888, "during": "39.436 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 128}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 1000.0, 'prompt_num': 50000}", "log time": "2024-10-26 13:34:29.542966"}{"0": {"event_name": "Query", "start_timestamp": 14514302.352974685, "env_timestamp": 14514692.191478511, "during": "389.839 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 128}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 100.0, 'prompt_num': 50000}", "log time": "2024-10-26 13:48:55.371126"}{"0": {"event_name": "Query", "start_timestamp": 14514709.627644535, "env_timestamp": 14514904.62277042, "during": "194.995 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 128}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 200.0, 'prompt_num': 50000}", "log time": "2024-10-26 13:52:27.802572"}{"0": {"event_name": "Query", "start_timestamp": 14514921.52329474, "env_timestamp": 14515051.58263445, "during": "130.059 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 128}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 300.0, 'prompt_num': 50000}", "log time": "2024-10-26 13:54:54.761569"}{"0": {"event_name": "Query", "start_timestamp": 14515072.239297325, "env_timestamp": 14515169.852023378, "during": "97.613 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 128}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 400.0, 'prompt_num': 50000}", "log time": "2024-10-26 13:56:53.031585"}{"0": {"event_name": "Query", "start_timestamp": 14515186.840695169, "env_timestamp": 14515264.990851823, "during": "78.15 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 128}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 500.0, 'prompt_num': 50000}", "log time": "2024-10-26 13:58:28.171391"}{"0": {"event_name": "Query", "start_timestamp": 14515282.073259402, "env_timestamp": 14515385.342162449, "during": "103.269 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 128}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 600.0, 'prompt_num': 50000}", "log time": "2024-10-26 14:00:28.521489"}{"0": {"event_name": "Query", "start_timestamp": 14515402.055671047, "env_timestamp": 14515504.784251511, "during": "102.729 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 128}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 700.0, 'prompt_num': 50000}", "log time": "2024-10-26 14:02:27.963550"}{"0": {"event_name": "Query", "start_timestamp": 14515521.523565577, "env_timestamp": 14515570.50740532, "during": "48.984 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 128}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 800.0, 'prompt_num': 50000}", "log time": "2024-10-26 14:03:33.687306"}{"0": {"event_name": "Query", "start_timestamp": 14515587.511162812, "env_timestamp": 14515686.45051372, "during": "98.939 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 128}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 900.0, 'prompt_num': 50000}", "log time": "2024-10-26 14:05:29.630025"}{"0": {"event_name": "Query", "start_timestamp": 14515703.9519756, "env_timestamp": 14515749.088342093, "during": "45.136 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 128}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 1000.0, 'prompt_num': 50000}", "log time": "2024-10-26 14:06:32.267968"}{"0": {"event_name": "Query", "start_timestamp": 14515766.3846845, "env_timestamp": 14515866.27465864, "during": "99.89 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 128}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 1500.0, 'prompt_num': 50000}", "log time": "2024-10-26 14:08:29.453993"}{"0": {"event_name": "Query", "start_timestamp": 14515884.02935645, "env_timestamp": 14515929.378143644, "during": "45.349 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 128}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 2000.0, 'prompt_num': 50000}", "log time": "2024-10-26 14:09:32.557352"}