{"0": {"event_name": "Query", "start_timestamp": 14592657.748860205, "env_timestamp": 14593078.482001496, "during": "420.733 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 128}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 100.0, 'prompt_num': 5000}", "log time": "2024-10-27 11:35:18.234058"}{"0": {"event_name": "Query", "start_timestamp": 14593093.961687196, "env_timestamp": 14593348.830603298, "during": "254.869 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 128}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 200.0, 'prompt_num': 5000}", "log time": "2024-10-27 11:39:48.582865"}{"0": {"event_name": "Query", "start_timestamp": 14593363.740940584, "env_timestamp": 14593569.84824046, "during": "206.107 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 128}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 300.0, 'prompt_num': 5000}", "log time": "2024-10-27 11:43:29.600297"}{"0": {"event_name": "Query", "start_timestamp": 14593584.51709192, "env_timestamp": 14593769.246807467, "during": "184.73 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 128}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 400.0, 'prompt_num': 5000}", "log time": "2024-10-27 11:46:48.998766"}{"0": {"event_name": "Query", "start_timestamp": 14593784.28143516, "env_timestamp": 14593953.24271727, "during": "168.961 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 128}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 500.0, 'prompt_num': 5000}", "log time": "2024-10-27 11:49:52.994821"}{"0": {"event_name": "Query", "start_timestamp": 14593968.464957844, "env_timestamp": 14594127.67575791, "during": "159.211 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 128}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 600.0, 'prompt_num': 5000}", "log time": "2024-10-27 11:52:47.427869"}{"0": {"event_name": "Query", "start_timestamp": 14594142.624019671, "env_timestamp": 14594296.250523355, "during": "153.627 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 128}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 700.0, 'prompt_num': 5000}", "log time": "2024-10-27 11:55:36.002786"}{"0": {"event_name": "Query", "start_timestamp": 14594311.577642804, "env_timestamp": 14594458.05073638, "during": "146.473 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 128}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 800.0, 'prompt_num': 5000}", "log time": "2024-10-27 11:58:17.802850"}{"0": {"event_name": "Query", "start_timestamp": 14594473.70649417, "env_timestamp": 14594619.094387509, "during": "145.388 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 128}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 900.0, 'prompt_num': 5000}", "log time": "2024-10-27 12:00:58.846347"}{"0": {"event_name": "Query", "start_timestamp": 14594634.748883108, "env_timestamp": 14594773.112679819, "during": "138.364 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 128}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 1000.0, 'prompt_num': 5000}", "log time": "2024-10-27 12:03:32.864571"}{"0": {"event_name": "Query", "start_timestamp": 14594789.21792982, "env_timestamp": 14594926.360574637, "during": "137.143 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 128}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 1500.0, 'prompt_num': 5000}", "log time": "2024-10-27 12:06:06.112737"}{"0": {"event_name": "Query", "start_timestamp": 14594941.973854108, "env_timestamp": 14595075.861201232, "during": "133.887 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 128}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 2000.0, 'prompt_num': 5000}", "log time": "2024-10-27 12:08:35.613284"}{"0": {"event_name": "Query", "start_timestamp": 14604572.109577077, "env_timestamp": 14604720.593327424, "during": "148.484 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 128}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 1000.0, 'prompt_num': 5000}", "log time": "2024-10-27 14:49:20.345896"}