{"0": {"event_name": "Query", "start_timestamp": 13988294.043526229, "env_timestamp": 13988516.949959377, "during": "222.906 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 1024}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 1000.0, 'prompt_num': 500}", "log time": "2024-10-20 11:39:22.405945"}{"0": {"event_name": "Query", "start_timestamp": 13989085.70031688, "env_timestamp": 13989116.67068023, "during": "30.97 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 1024}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 50, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 1000.0, 'prompt_num': 50}", "log time": "2024-10-20 11:49:28.087820"}{"0": {"event_name": "Query", "start_timestamp": 13989308.297583397, "env_timestamp": 13989328.728312736, "during": "20.431 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 1024}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 50, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 1000.0, 'prompt_num': 50}", "log time": "2024-10-20 11:53:20.940733"}{"0": {"event_name": "Query", "start_timestamp": 13989577.525898676, "env_timestamp": 13989595.694381379, "during": "18.168 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 1024}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 50, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 1000.0, 'prompt_num': 50}", "log time": "2024-10-20 11:57:30.449815"}{"0": {"event_name": "Query", "start_timestamp": 13989660.71811988, "env_timestamp": 13989678.661690086, "during": "17.944 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 1024}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 50, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 1000.0, 'prompt_num': 50}", "log time": "2024-10-20 11:59:01.399520"}{"0": {"event_name": "Query", "start_timestamp": 13989940.039035762, "env_timestamp": 13989958.594898583, "during": "18.556 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 1024}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 50, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 1000.0, 'prompt_num': 50}", "log time": "2024-10-20 12:03:24.040763"}{"0": {"event_name": "Query", "start_timestamp": 13989940.039035762, "env_timestamp": 13989958.594898583, "during": "18.556 s"}, "model path": ["/root/autodl-tmp/Llama-3.2-1B"], "server_config": ["{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 1024}"], "prompt_config": ["{'seed': 0, 'surplus_prompts_num': 50, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 1000.0, 'prompt_num': 50}"], "log time": ["2024-10-20 12:03:24.040763"]}{"0": {"event_name": "Query", "start_timestamp": 13990065.446205651, "env_timestamp": 13990084.344042484, "during": "18.898 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 1024}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 50, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 1000.0, 'prompt_num': 50}", "log time": "2024-10-20 12:05:29.789689"}{"0": {"event_name": "Query", "start_timestamp": 13990231.129571471, "env_timestamp": 13990251.075854223, "during": "19.946 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 1024}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 50, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 1000.0, 'prompt_num': 500}", "log time": "2024-10-20 12:08:16.521648"}{"0": {"event_name": "Query", "start_timestamp": 13990296.650917048, "env_timestamp": 13990494.37365206, "during": "197.723 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 1024}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 1000.0, 'prompt_num': 500}", "log time": "2024-10-20 12:12:19.829032"}{"0": {"event_name": "Query", "start_timestamp": 14005182.843914673, "env_timestamp": 14005636.442654386, "during": "453.599 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 1024}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 100.0, 'prompt_num': 500}", "log time": "2024-10-20 16:24:39.622442"}{"0": {"event_name": "Query", "start_timestamp": 14005930.831174484, "env_timestamp": 14006151.125234757, "during": "220.294 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 1024}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 500.0, 'prompt_num': 500}", "log time": "2024-10-20 16:33:14.304658"}{"0": {"event_name": "Query", "start_timestamp": 14006225.741795337, "env_timestamp": 14006408.608820988, "during": "182.867 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 1024}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 1500.0, 'prompt_num': 500}", "log time": "2024-10-20 16:37:31.794361"}{"model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 1024}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 10.0, 'prompt_num': 500}", "log time": "2024-10-22 09:33:52.398786"}{"0": {"event_name": "Query", "start_timestamp": 14154306.32716372, "env_timestamp": 14154568.427363446, "during": "262.1 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 1024}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 200.0, 'prompt_num': 500}", "log time": "2024-10-22 09:46:51.606678"}{"0": {"event_name": "Query", "start_timestamp": 14154987.700188622, "env_timestamp": 14155166.740824288, "during": "179.041 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 1024}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 400.0, 'prompt_num': 500}", "log time": "2024-10-22 09:56:49.920469"}{"0": {"event_name": "Query", "start_timestamp": 14156165.809842965, "env_timestamp": 14156324.169218834, "during": "158.359 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 1024}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 600.0, 'prompt_num': 500}", "log time": "2024-10-22 10:16:07.348570"}{"0": {"event_name": "Query", "start_timestamp": 14156380.320262672, "env_timestamp": 14156528.423475012, "during": "148.103 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 1024}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 800.0, 'prompt_num': 500}", "log time": "2024-10-22 10:19:31.602973"}{"0": {"event_name": "Query", "start_timestamp": 14156639.641145945, "env_timestamp": 14156786.366848228, "during": "146.726 s"}, "model path": "/root/autodl-tmp/Llama-3.2-1B", "server_config": "{'stream': True, 'ignore_eos': False, 'qps': 1.0, 'host': 'localhost', 'port': 8000, 'temperature': 0, 'max_tokens': 1024}", "prompt_config": "{'seed': 0, 'surplus_prompts_num': 500, 'use_burstgpt': True, 'burstgpt_path': '../data/BurstGPT_1.csv', 'conv_or_api': 'conv', 'scale': 900.0, 'prompt_num': 500}", "log time": "2024-10-22 10:23:49.546773"}